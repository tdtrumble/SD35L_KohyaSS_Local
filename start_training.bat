accelerate launch ^
--mixed_precision bf16 ^
--num_cpu_threads_per_process 1 sd-scripts/sd3_train_network.py ^
--pretrained_model_name_or_path "pathto/sd3.5_large.safetensors" ^
--clip_l "pathto/clip_l.safetensors" ^
--clip_g "pathto/clip_g.safetensors" ^
--t5xxl "pathto/t5xxl_fp16.safetensors" ^
--cache_latents ^
--cache_latents_to_disk ^
--save_model_as safetensors ^
--sdpa ^
--persistent_data_loader_workers ^
--max_data_loader_n_workers 2 ^
--seed 123456 ^
--gradient_checkpointing ^
--mixed_precision bf16 ^
--save_precision bf16 ^
--network_module networks.lora_sd3 ^
--network_dim 128 ^
--network_alpha 128 ^
--optimizer_type Adafactor ^
--optimizer_args "scale_parameter=False" "relative_step=False" "warmup_init=False" "weight_decay=0.01" ^
--lr_scheduler constant_with_warmup ^
--lr_warmup 5 ^
--learning_rate 3e-05 ^
--network_train_unet_only ^
--cache_text_encoder_outputs ^
--cache_text_encoder_outputs_to_disk ^
--disable_mmap_load_safetensors ^
--highvram ^
--max_train_epochs 300 ^
--save_every_n_epochs 10 ^
--enable_scaled_pos_embed ^
--dataset_config "pathto/Kohya_Dataset_Config.toml" ^
--output_dir "pathto/output_dir" ^
--output_name outputLORA ^
--sample_every_n_epochs 10 ^
--sample_prompts "pathto/Kohya_Sample_Prompts.txt" ^
--sample_sampler euler
